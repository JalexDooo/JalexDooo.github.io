@article{li_taunet_2022,
 abstract = {Automated segmentation of cardiac pathology in MRI plays a signiﬁcant role for diagnosis and treatment of some cardiac disease. In clinical practice, multi-modality MRI is widely used to improve the cardiac pathology segmentation, because it can provide multiple or complementary information. Recently, deep learning methods have presented implausible performance in multi-modality medical image segmentation. However, how to fuse the underlying multi-modality information effectively to segment the pathology with irregular shapes and small region at random locations, is still a challenge task. In this paper, a triple-attention-based multi-modality MRI fusion U-Net was proposed to learn complex relationship between different modalities and pay more attention on shape information, thus to achieve improved pathology segmentation. First, three independent encoders and one fusion encoder were applied to extract speciﬁc and multiple modality features. Secondly, we concatenate the modality feature maps and use the channel attention to fuse speciﬁc modal information at every stage of the three dedicate independent encoders, then the three single modality feature maps and channel attention feature maps are together concatenated to the decoder path. Spatial attention was adopted in decoder path to capture the correlation of various positions. Once more, we employ shape attention to focus shape-dependent information. Lastly, the training approach is made efﬁcient by introducing deep supervision mechanism with object contextual representations block to ensure precisely boundary prediction. Our proposed network was evaluated on the public MICCAI 2020 Myocardial pathology segmentation dataset which involves patients suffering from myocardial infarction. Experiments on the dataset with three modalities demonstrate the effectiveness of fusion mode of our model, and attention mechanism can integrate various modality information well. We demonstrated that such a deep learning approach could better fuse complementary information to improve the segmentation performance of cardiac pathology.},
 author = {Li, Dapeng and Peng, Yanjun and Guo, Yanfei and Sun, Jindong},
 doi = {10.1007/s40747-022-00660-6},
 file = {Li et al. - 2022 - TAUNet a triple-attention-based multi-modality MRI fusion U-net for cardiac pathology segmentation.pdf:/Users/jontysun/Zotero/storage/PMEFXK9A/Li et al. - 2022 - TAUNet a triple-attention-based multi-modality MRI fusion U-net for cardiac pathology segmentation.pdf:application/pdf},
 issn = {2199-4536, 2198-6053},
 journal = {Complex & Intelligent Systems},
 keywords = {/unread, /未读},
 language = {en},
 month = {June},
 number = {3},
 pages = {2489--2505},
 shorttitle = {TAUNet},
 title = {TAUNet: a triple-attention-based multi-modality MRI fusion U-net for cardiac pathology segmentation},
 url = {https://link.springer.com/10.1007/s40747-022-00660-6},
 urldate = {2025-11-12},
 volume = {8},
 year = {2022}
}
